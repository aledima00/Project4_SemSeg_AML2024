{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aledima00/Project4_SemSeg_AML2024/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGAibz4oZbs"
      },
      "source": [
        "# Project 4 - Semantic Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's download dataset, that is already split in \"Train\", \"Test\" and \"Val\" modules"
      ],
      "metadata": {
        "id": "GaksjqH-t7sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "id": "NPe9UMf8DtRL",
        "outputId": "8b46d9ee-8db1-4840-bbff-b8684be5e607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from skimage.io import imread\n",
        "import logging\n",
        "from enum import Enum\n",
        "import gdown\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3s8kdM5oGGr1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General Configuration:"
      ],
      "metadata": {
        "id": "f3N9EoQoVgC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DBG = False                   # set to True for debug mode (lighter execution + dbg prints)\n",
        "CONFIG_DATASET = True         # set to True to download and config all dataset resources\n",
        "CONFIG_DEEPLABV2 = True       # set to True to download and config all DeepLabv2 resources\n",
        "CONFIG_PIDNET = True          # set to True to download and config all PIDNET resources\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "TRAIN_PATH = \"Train\"          # path of the train folder\n",
        "VAL_PATH = \"Val\"              # path of the val folder\n",
        "TEST_PATH = \"Test\"            # path of the test folder\n",
        "\n",
        "DEEPLABV2_WEIGHTS_PATH = \"deeplabv2-pretrain-weights.pth\"  # path of the deeplabv2 folder\n",
        "PIDNET_WEIGHTS_PATH = \"PIDNet/pretrained_models/imagenet/imagenet.pth\""
      ],
      "metadata": {
        "id": "yacl9RktR8Fb",
        "outputId": "493b3422-f887-487e-ab4f-f0007c23b580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download datasets:"
      ],
      "metadata": {
        "id": "BPING-HIYj5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QlswjyfJoZbu"
      },
      "outputs": [],
      "source": [
        "def config_generic_dataset(DS_PATHNAME,URL):\n",
        "  !rm -rf {DS_PATHNAME}\n",
        "  ZIP_PATH = DS_PATHNAME + \".zip\"\n",
        "  !rm {ZIP_PATH}\n",
        "  !wget -O {ZIP_PATH} {URL}\n",
        "  !unzip {ZIP_PATH} | tail -n 3\n",
        "  !rm {ZIP_PATH}\n",
        "\n",
        "def config_train_dataset():\n",
        "  config_generic_dataset(TRAIN_PATH, \"https://zenodo.org/records/5706578/files/Train.zip?download=1\")\n",
        "def config_val_dataset():\n",
        "  config_generic_dataset(VAL_PATH, \"https://zenodo.org/records/5706578/files/Val.zip?download=1\")\n",
        "def config_test_dataset():\n",
        "  config_generic_dataset(TEST_PATH, \"https://zenodo.org/records/5706578/files/Test.zip?download=1\")\n",
        "\n",
        "def config_all_dataset(*,force=False):\n",
        "  print(\"Dowloading and Configuring Dataset\")\n",
        "  if force or (not os.path.exists(TRAIN_PATH)):\n",
        "    config_train_dataset()\n",
        "  if force or (not os.path.exists(VAL_PATH)):\n",
        "    config_val_dataset()\n",
        "  if force or (not os.path.exists(TEST_PATH)):\n",
        "    config_test_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download and configure deeplabv2 model library (_with R101 backbone_) and the pretrain weights:"
      ],
      "metadata": {
        "id": "OYvs6ukiaWXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def config_deeplabv2_model():\n",
        "  print(\"Dowloading and Configuring DeepLabv2 Model\")\n",
        "  import sys\n",
        "  import gdown\n",
        "  !rm -rf \"MLDL2024_project1\"\n",
        "  !git clone https://github.com/Gabrysse/MLDL2024_project1.git\n",
        "  sys.path.append(\"/content/MLDL2024_project1/\")\n",
        "  gdown.download(\"https://drive.google.com/uc?id=1ZX0UCXvJwqd2uBGCX7LI2n-DfMg3t74v\", DEEPLABV2_WEIGHTS_PATH, quiet=False)\n"
      ],
      "metadata": {
        "id": "ILWYQBnQZvj8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config pidnet..."
      ],
      "metadata": {
        "id": "sSV3px5dN3kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def config_pidnet():\n",
        "  import sys\n",
        "  import gdown\n",
        "  print(\"Dowloading and Configuring PIDNET Model\")\n",
        "  !rm -rf \"PIDNet\"\n",
        "  !git clone https://github.com/XuJiacong/PIDNet.git\n",
        "  sys.path.append(\"/content/PIDNet/\")\n",
        "  gdown.download(\"https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\", PIDNET_WEIGHTS_PATH, quiet=False)\n"
      ],
      "metadata": {
        "id": "ltKuPIAaN5WC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if CONFIG_DATASET:\n",
        "  config_all_dataset()\n",
        "if CONFIG_DEEPLABV2:\n",
        "  config_deeplabv2_model()\n",
        "if CONFIG_PIDNET:\n",
        "  config_pidnet()"
      ],
      "metadata": {
        "id": "jklZ1NAorsGq",
        "outputId": "5722168b-51d5-436d-e1eb-23564f26579d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowloading and Configuring Dataset\n",
            "Dowloading and Configuring DeepLabv2 Model\n",
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 34 (delta 8), reused 4 (delta 4), pack-reused 16 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34/34), 12.06 KiB | 6.03 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZX0UCXvJwqd2uBGCX7LI2n-DfMg3t74v\n",
            "From (redirected): https://drive.google.com/uc?id=1ZX0UCXvJwqd2uBGCX7LI2n-DfMg3t74v&confirm=t&uuid=f8754b4b-ce6c-4625-bc33-2b6a8f3b0d72\n",
            "To: /content/deeplabv2-pretrain-weights.pth\n",
            "100%|██████████| 177M/177M [00:01<00:00, 91.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowloading and Configuring PIDNET Model\n",
            "Cloning into 'PIDNet'...\n",
            "remote: Enumerating objects: 386, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 386 (delta 131), reused 125 (delta 125), pack-reused 193 (from 1)\u001b[K\n",
            "Receiving objects: 100% (386/386), 212.80 MiB | 17.05 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\n",
            "To: /content/PIDNet/pretrained_models/imagenet/imagenet.pth\n",
            "100%|██████████| 38.1M/38.1M [00:00<00:00, 183MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colorama import Fore, Back, Style\n",
        "def dbgp(name,value):\n",
        "  \"\"\" Debug print function \"\"\"\n",
        "  if DBG:\n",
        "    print(f\"{Fore.BLACK}{Back.GREEN}{Style.BRIGHT}{name}:\\t{value}{Fore.RESET}{Back.RESET}{Style.RESET_ALL}\")"
      ],
      "metadata": {
        "id": "Lbd-G8xDYRu5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "T30UDU6NBlLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset class and filter urban pictures..."
      ],
      "metadata": {
        "id": "O79ygl6vuWZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 2 if DBG else 32\n",
        "LR = 0.001           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 4e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = [25, 75, 150] # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down"
      ],
      "metadata": {
        "id": "rS-RMBUf9x10"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for training phase\n",
        "train_image_transform = transforms.Compose([\n",
        "    transforms.Resize(256),       # Resizes short size of the PIL image to 256\n",
        "    transforms.CenterCrop(224),   # Crops a central square patch of the image\n",
        "                                  # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                  # Remember this when applying different transformations, otherwise you get an error\n",
        "    transforms.ToTensor(),        # Turn PIL Image to torch.Tensor\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # Normalize as per ImageNet stats\n",
        "])\n",
        "\n",
        "# Define transforms for the evaluation phase\n",
        "test_image_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # Normalize as per ImageNet stats\n",
        "])\n",
        "\n",
        "# Masks should not be normalized or resized with interpolation\n",
        "target_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Lambda(lambda mask: torch.tensor(np.array(mask), dtype=torch.int8)),\n",
        "])\n"
      ],
      "metadata": {
        "id": "IbuKjlvxKXiD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taken from official repo of LoveDA\n",
        "IGNORE_INDEX = -1\n",
        "COLOR_MAP = {\n",
        "    IGNORE_INDEX:\"IGNORE\",\n",
        "    0:\"Background\",\n",
        "    1:\"Building\",\n",
        "    2:\"Road\",\n",
        "    3:\"Water\",\n",
        "    4:\"Barren\",\n",
        "    5:\"Forest\",\n",
        "    6:\"Agricultural\"\n",
        "}\n",
        "CLASSES = list(key for key in COLOR_MAP.keys() if COLOR_MAP[key] != \"IGNORE\")"
      ],
      "metadata": {
        "id": "ke4pX0Bvpohi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pil_loader(path,*,format:str=\"RGB\"):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert(format)\n",
        "\n",
        "class DataType(Enum):\n",
        "  RURAL = 0\n",
        "  URBAN = 1\n",
        "\n",
        "class LoveDA(Dataset):\n",
        "  def __init__(self, basedir, data_type:DataType, transforms=None, target_transform=None):\n",
        "    #super(LoveDA, self).__init__(basedir, transforms, target_transform) # should we do this??\n",
        "    if data_type == DataType.RURAL:\n",
        "        self.base_path = os.path.join(basedir, \"Rural\")\n",
        "    else: #data_type == DataType.URBAN:\n",
        "        self.base_path = os.path.join(basedir, \"Urban\")\n",
        "\n",
        "\n",
        "    # list of integers that identifies paths relative to both images_png and masks_png\n",
        "    self.int_pathrefs = os.listdir(os.path.join(self.base_path, \"images_png\"))\n",
        "    self.int_pathrefs = list(int(st.split(\".\")[0]) for st in self.int_pathrefs)\n",
        "\n",
        "    # DEBUG PRINT\n",
        "    if DBG:\n",
        "      self.int_pathrefs = self.int_pathrefs[:15] # limit the dataset for debug\n",
        "    #dbgp(\"int_pathrefs\", self.int_pathrefs)\n",
        "\n",
        "    self.transforms = transforms\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    assert idx < len(self), 'Index out of range'\n",
        "    image_path = os.path.join(self.base_path, \"images_png\", str(self.int_pathrefs[idx]) + \".png\")\n",
        "    mask_path = os.path.join(self.base_path, \"masks_png\", str(self.int_pathrefs[idx]) + \".png\")\n",
        "    image = pil_loader(image_path,format=\"RGB\")\n",
        "    mask = pil_loader(mask_path,format=\"L\")\n",
        "\n",
        "    if self.transforms is not None:\n",
        "      image = self.transforms(image)\n",
        "    if self.target_transform is not None:\n",
        "      mask = self.target_transform(mask)\n",
        "\n",
        "    mask -= 1\n",
        "\n",
        "    # DEBUG PRINT\n",
        "    #dbgp(\"post-transform image\", image)\n",
        "    #dbgp(\"post-transform mask\", mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.int_pathrefs)\n"
      ],
      "metadata": {
        "id": "-pTgwB0k1wWA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Urban Datasets (train, val, test)\n",
        "urban_train = LoveDA(TRAIN_PATH, DataType.URBAN, transforms=train_image_transform, target_transform=target_transform)\n",
        "urban_val = LoveDA(VAL_PATH, DataType.URBAN, transforms=test_image_transform, target_transform=target_transform)\n",
        "urban_test = LoveDA(TEST_PATH, DataType.URBAN, transforms=test_image_transform, target_transform=target_transform)\n",
        "\n",
        "# Urban Dataloaders (train, val, test)\n",
        "\n",
        "NUM_WORKERS = 2 if DBG else 4\n",
        "urban_train_dataloader = DataLoader(urban_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
        "urban_val_dataloader = DataLoader(urban_val, shuffle=False, num_workers=NUM_WORKERS, drop_last=False)\n",
        "urban_test_dataloader = DataLoader(urban_test, shuffle=False, num_workers=NUM_WORKERS, drop_last=False)"
      ],
      "metadata": {
        "id": "AeG5O3GoDj5b",
        "outputId": "f66c87b1-bf15-4fae-ebf5-f68b240ddac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get DeepLabv2 model with pretrain weights:"
      ],
      "metadata": {
        "id": "PklC_MDk1z31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from MLDL2024_project1.models.deeplabv2 import deeplabv2\n",
        "\n",
        "model = deeplabv2.get_deeplab_v2(num_classes=NUM_CLASSES,pretrain=True,pretrain_model_path=DEEPLABV2_WEIGHTS_PATH)"
      ],
      "metadata": {
        "id": "CCfB1vwkWB7e",
        "outputId": "6c5d352b-43b3-48cf-fa3d-f7abf44871f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deeplab pretraining loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MLDL2024_project1/models/deeplabv2/deeplabv2.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_state_dict = torch.load(pretrain_model_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer, Loss, ecc."
      ],
      "metadata": {
        "id": "eR_jhjxTcxB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enable validation during training\n",
        "validate = True\n",
        "\n",
        "model.train(True)\n",
        "model.multi_level = False # ask in class\n",
        "for params in model.get_1x_lr_params_no_scale():\n",
        "  params.requires_grad = False # no training in Backbone\n",
        "for params in model.get_10x_lr_params():\n",
        "  params.requires_grad = True # training in classifiers\n",
        "\n",
        "\n",
        "model = model.to(DEVICE) # switch to GPU\n",
        "\n",
        "#Loss (as said in DeepLabv2 docs)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Opt\n",
        "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer_fn = optim.Adam(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY, eps=1e-4)\n",
        "\n",
        "#Scheduler\n",
        "optim_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=STEP_SIZE, gamma=GAMMA)\n"
      ],
      "metadata": {
        "id": "gfXbShPFcwrE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "zrh_HJ0xbfTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from torch.backends import cudnn\n",
        "warnings.filterwarnings('ignore')\n",
        "train_iter = 0\n",
        "val_iter = 0\n",
        "\n",
        "trainSamples = len(urban_train) - (len(urban_train) % BATCH_SIZE)\n",
        "val_samples = len(urban_val)\n",
        "iterPerEpoch = len(urban_train_dataloader)\n",
        "val_steps = len(urban_val_dataloader)\n",
        "\n",
        "cudnn.benchmark\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "model_checkpoint = \"model\" #name\n",
        "model.train(True)\n",
        "EPSILON_IOU = 1e-7\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    avg_IoU = 0\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(urban_train_dataloader):\n",
        "        train_iter += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "\n",
        "        # feeds in model\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = targets.long().to(device=DEVICE)\n",
        "\n",
        "        output_logits,_,_ = model(inputs)\n",
        "\n",
        "        # compute loss\n",
        "        loss = loss_fn(output_logits, labels)\n",
        "\n",
        "        # backward loss and optimizer step\n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "\n",
        "        #compute the training accuracy\n",
        "        _, predicted = torch.max(output_logits.data, 1)\n",
        "\n",
        "        #dbgp(\"predicted\", predicted)\n",
        "        #dbgp(\"labels\", labels)\n",
        "\n",
        "        #calcolo del IoU per ogni classe (da controllare)\n",
        "        intersection_per_class = dict()\n",
        "        union_per_class = dict()\n",
        "        class_IoUs = dict()\n",
        "\n",
        "        mIoU=0\n",
        "\n",
        "        for cls in CLASSES:\n",
        "          true_mask = (labels == cls)  # Crea una maschera booleana per la classe `cls` nel target\n",
        "          pred_mask = (predicted == cls)  # Crea una maschera booleana per la classe `cls` nelle predizioni\n",
        "\n",
        "          # Calcola l'intersezione e l'unione per quella classe\n",
        "          intersection = torch.logical_and(true_mask, pred_mask).sum().item()\n",
        "          union = torch.logical_or(true_mask, pred_mask).sum().item()\n",
        "\n",
        "          # Aggiungi i valori all'array totale di intersezione e unione per ogni classe\n",
        "          intersection_per_class[cls] = intersection\n",
        "          union_per_class[cls] = union\n",
        "\n",
        "          # Calcolo IoU per ogni classe\n",
        "          class_IoUs[cls] = intersection_per_class[cls] / (union_per_class[cls]+EPSILON_IOU)\n",
        "\n",
        "        # Calcola la mIoU (mean IoU)\n",
        "        mIoU = sum(class_IoUs.values()) / NUM_CLASSES\n",
        "        avg_IoU += mIoU\n",
        "\n",
        "        step_loss = loss.data.item()\n",
        "        epoch_loss += step_loss\n",
        "        if train_iter % (iterPerEpoch/2) == 0:\n",
        "          # Stampa l'IoU per ogni classe\n",
        "          print(Fore.CYAN + Style.NORMAL + \"Class-wise IoUs:\"+ Style.RESET_ALL)\n",
        "          for cls in CLASSES:\n",
        "            print(f\"Class {cls} ({COLOR_MAP[cls]}): IoU = {class_IoUs[cls]:.3f}\"+ Style.RESET_ALL)\n",
        "\n",
        "          # Stampa la mean IoU\n",
        "          print(Fore.GREEN + Style.DIM + f\"Mean IoU (mIoU): {mIoU:.3f}\" + Style.RESET_ALL)\n",
        "          print(Fore.WHITE + Style.DIM + 'Train: Epoch = {} | Step = {} | Step Loss = {:.3f}'.format(epoch + 1, train_iter, step_loss)+ Style.RESET_ALL)\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    avg_IoU = (avg_IoU/iterPerEpoch)\n",
        "\n",
        "    print(Fore.BLACK + Back.GREEN + Style.BRIGHT + 'Train: Epoch = {} | mean Loss = {:.3f} | mean-IoU = {:.3f}'.format(epoch + 1, avg_loss, avg_IoU)+Style.RESET_ALL)\n",
        "    \"\"\"\n",
        "    #train_logger.add_epoch_data(epoch+1, trainAccuracy, avg_loss)\n",
        "\n",
        "    if validate:\n",
        "        if (epoch+1) % 1 == 0:\n",
        "            model.train(False)\n",
        "            val_loss_epoch = 0\n",
        "            numCorr = 0\n",
        "            for j, (inputs, targets) in enumerate(val_loader):\n",
        "                val_iter += 1\n",
        "                inputVariable = inputs.permute(1, 0, 2, 3, 4).to(DEVICE)\n",
        "                labelVariable = targets.to(DEVICE)\n",
        "\n",
        "                output_label, _ = model(inputVariable)\n",
        "                val_loss = loss_fn(output_label, labelVariable)\n",
        "\n",
        "                val_loss_step = val_loss.data.item()\n",
        "                val_loss_epoch += val_loss_step\n",
        "                _, predicted = torch.max(output_label.data, 1)\n",
        "                numCorr += torch.sum(predicted == labelVariable.data).data.item()\n",
        "                #val_logger.add_step_data(val_iter, numCorr, val_loss_step)\n",
        "\n",
        "            val_accuracy = (numCorr / val_samples) * 100\n",
        "            avg_val_loss = val_loss_epoch / val_steps\n",
        "\n",
        "            print(Fore.GREEN + 'Val: Epoch = {} | Loss {:.3f} | Accuracy = {:.3f}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            if val_accuracy > min_accuracy:\n",
        "                print(\"[||| NEW BEST on val||||]\")\n",
        "                save_path_model = os.path.join(model_folder, model_checkpoint)\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                min_accuracy = val_accuracy\n",
        "\"\"\"\n",
        "    optim_scheduler.step()\n"
      ],
      "metadata": {
        "id": "LclZQhQQVLt7",
        "outputId": "d8ffe9e6-e4a9-4896-d14f-6d85f954bf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.417\u001b[0m\n",
            "Class 1 (Building): IoU = 0.211\u001b[0m\n",
            "Class 2 (Road): IoU = 0.157\u001b[0m\n",
            "Class 3 (Water): IoU = 0.323\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.236\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.114\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.000\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.208\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 1 | Step = 18 | Step Loss = 3.148\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.420\u001b[0m\n",
            "Class 1 (Building): IoU = 0.274\u001b[0m\n",
            "Class 2 (Road): IoU = 0.313\u001b[0m\n",
            "Class 3 (Water): IoU = 0.187\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.196\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.176\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.000\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.224\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 1 | Step = 36 | Step Loss = 2.247\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 1 | mean Loss = 3.624 | mean-IoU = 0.180\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.492\u001b[0m\n",
            "Class 1 (Building): IoU = 0.239\u001b[0m\n",
            "Class 2 (Road): IoU = 0.311\u001b[0m\n",
            "Class 3 (Water): IoU = 0.142\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.451\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.249\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.095\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.283\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 2 | Step = 54 | Step Loss = 1.587\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.368\u001b[0m\n",
            "Class 1 (Building): IoU = 0.375\u001b[0m\n",
            "Class 2 (Road): IoU = 0.310\u001b[0m\n",
            "Class 3 (Water): IoU = 0.187\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.385\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.310\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.513\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.350\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 2 | Step = 72 | Step Loss = 1.543\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 2 | mean Loss = 1.537 | mean-IoU = 0.334\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.474\u001b[0m\n",
            "Class 1 (Building): IoU = 0.321\u001b[0m\n",
            "Class 2 (Road): IoU = 0.340\u001b[0m\n",
            "Class 3 (Water): IoU = 0.139\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.603\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.233\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.662\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.396\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 3 | Step = 90 | Step Loss = 1.229\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.543\u001b[0m\n",
            "Class 1 (Building): IoU = 0.231\u001b[0m\n",
            "Class 2 (Road): IoU = 0.300\u001b[0m\n",
            "Class 3 (Water): IoU = 0.491\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.393\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.208\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.151\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.331\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 3 | Step = 108 | Step Loss = 1.266\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 3 | mean Loss = 1.223 | mean-IoU = 0.398\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.487\u001b[0m\n",
            "Class 1 (Building): IoU = 0.407\u001b[0m\n",
            "Class 2 (Road): IoU = 0.425\u001b[0m\n",
            "Class 3 (Water): IoU = 0.773\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.470\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.299\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.394\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.465\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 4 | Step = 126 | Step Loss = 1.032\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.443\u001b[0m\n",
            "Class 1 (Building): IoU = 0.383\u001b[0m\n",
            "Class 2 (Road): IoU = 0.386\u001b[0m\n",
            "Class 3 (Water): IoU = 0.283\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.473\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.405\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.667\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.434\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 4 | Step = 144 | Step Loss = 1.074\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 4 | mean Loss = 1.099 | mean-IoU = 0.449\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.522\u001b[0m\n",
            "Class 1 (Building): IoU = 0.355\u001b[0m\n",
            "Class 2 (Road): IoU = 0.458\u001b[0m\n",
            "Class 3 (Water): IoU = 0.456\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.701\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.386\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.685\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.509\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 5 | Step = 162 | Step Loss = 0.935\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.578\u001b[0m\n",
            "Class 1 (Building): IoU = 0.339\u001b[0m\n",
            "Class 2 (Road): IoU = 0.417\u001b[0m\n",
            "Class 3 (Water): IoU = 0.535\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.465\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.441\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.753\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.504\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 5 | Step = 180 | Step Loss = 0.889\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 5 | mean Loss = 0.927 | mean-IoU = 0.479\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.486\u001b[0m\n",
            "Class 1 (Building): IoU = 0.264\u001b[0m\n",
            "Class 2 (Road): IoU = 0.396\u001b[0m\n",
            "Class 3 (Water): IoU = 0.797\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.523\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.360\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.722\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.507\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 6 | Step = 198 | Step Loss = 1.086\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.533\u001b[0m\n",
            "Class 1 (Building): IoU = 0.412\u001b[0m\n",
            "Class 2 (Road): IoU = 0.408\u001b[0m\n",
            "Class 3 (Water): IoU = 0.251\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.598\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.558\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.630\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.484\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 6 | Step = 216 | Step Loss = 0.915\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 6 | mean Loss = 0.958 | mean-IoU = 0.487\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.469\u001b[0m\n",
            "Class 1 (Building): IoU = 0.434\u001b[0m\n",
            "Class 2 (Road): IoU = 0.462\u001b[0m\n",
            "Class 3 (Water): IoU = 0.643\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.575\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.410\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.686\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.526\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 7 | Step = 234 | Step Loss = 0.958\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.617\u001b[0m\n",
            "Class 1 (Building): IoU = 0.351\u001b[0m\n",
            "Class 2 (Road): IoU = 0.510\u001b[0m\n",
            "Class 3 (Water): IoU = 0.647\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.672\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.512\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.457\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.538\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 7 | Step = 252 | Step Loss = 0.779\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 7 | mean Loss = 0.884 | mean-IoU = 0.505\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.569\u001b[0m\n",
            "Class 1 (Building): IoU = 0.404\u001b[0m\n",
            "Class 2 (Road): IoU = 0.443\u001b[0m\n",
            "Class 3 (Water): IoU = 0.562\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.661\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.324\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.626\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.513\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 8 | Step = 270 | Step Loss = 0.918\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.608\u001b[0m\n",
            "Class 1 (Building): IoU = 0.368\u001b[0m\n",
            "Class 2 (Road): IoU = 0.445\u001b[0m\n",
            "Class 3 (Water): IoU = 0.578\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.690\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.577\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.769\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.577\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 8 | Step = 288 | Step Loss = 0.754\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 8 | mean Loss = 0.835 | mean-IoU = 0.515\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.611\u001b[0m\n",
            "Class 1 (Building): IoU = 0.315\u001b[0m\n",
            "Class 2 (Road): IoU = 0.319\u001b[0m\n",
            "Class 3 (Water): IoU = 0.349\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.524\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.403\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.777\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.471\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 9 | Step = 306 | Step Loss = 0.928\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.527\u001b[0m\n",
            "Class 1 (Building): IoU = 0.485\u001b[0m\n",
            "Class 2 (Road): IoU = 0.442\u001b[0m\n",
            "Class 3 (Water): IoU = 0.676\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.356\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.392\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.641\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.503\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 9 | Step = 324 | Step Loss = 0.786\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 9 | mean Loss = 0.815 | mean-IoU = 0.527\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.647\u001b[0m\n",
            "Class 1 (Building): IoU = 0.369\u001b[0m\n",
            "Class 2 (Road): IoU = 0.495\u001b[0m\n",
            "Class 3 (Water): IoU = 0.699\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.661\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.470\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.598\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.563\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 10 | Step = 342 | Step Loss = 0.706\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.592\u001b[0m\n",
            "Class 1 (Building): IoU = 0.475\u001b[0m\n",
            "Class 2 (Road): IoU = 0.406\u001b[0m\n",
            "Class 3 (Water): IoU = 0.654\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.648\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.449\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.704\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.561\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 10 | Step = 360 | Step Loss = 0.733\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 10 | mean Loss = 0.784 | mean-IoU = 0.538\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.587\u001b[0m\n",
            "Class 1 (Building): IoU = 0.396\u001b[0m\n",
            "Class 2 (Road): IoU = 0.366\u001b[0m\n",
            "Class 3 (Water): IoU = 0.045\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.576\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.396\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.604\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.424\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 11 | Step = 378 | Step Loss = 0.863\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.538\u001b[0m\n",
            "Class 1 (Building): IoU = 0.461\u001b[0m\n",
            "Class 2 (Road): IoU = 0.469\u001b[0m\n",
            "Class 3 (Water): IoU = 0.555\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.665\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.398\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.888\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.568\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 11 | Step = 396 | Step Loss = 0.768\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 11 | mean Loss = 0.774 | mean-IoU = 0.541\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.445\u001b[0m\n",
            "Class 1 (Building): IoU = 0.524\u001b[0m\n",
            "Class 2 (Road): IoU = 0.427\u001b[0m\n",
            "Class 3 (Water): IoU = 0.698\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.495\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.260\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.865\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.531\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 12 | Step = 414 | Step Loss = 0.994\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.584\u001b[0m\n",
            "Class 1 (Building): IoU = 0.397\u001b[0m\n",
            "Class 2 (Road): IoU = 0.429\u001b[0m\n",
            "Class 3 (Water): IoU = 0.696\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.647\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.474\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.818\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.578\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 12 | Step = 432 | Step Loss = 0.788\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 12 | mean Loss = 0.822 | mean-IoU = 0.535\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.524\u001b[0m\n",
            "Class 1 (Building): IoU = 0.422\u001b[0m\n",
            "Class 2 (Road): IoU = 0.450\u001b[0m\n",
            "Class 3 (Water): IoU = 0.697\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.502\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.404\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.609\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.515\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 13 | Step = 450 | Step Loss = 0.884\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.595\u001b[0m\n",
            "Class 1 (Building): IoU = 0.415\u001b[0m\n",
            "Class 2 (Road): IoU = 0.381\u001b[0m\n",
            "Class 3 (Water): IoU = 0.362\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.594\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.317\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.512\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.454\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 13 | Step = 468 | Step Loss = 0.855\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 13 | mean Loss = 0.905 | mean-IoU = 0.520\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.585\u001b[0m\n",
            "Class 1 (Building): IoU = 0.412\u001b[0m\n",
            "Class 2 (Road): IoU = 0.459\u001b[0m\n",
            "Class 3 (Water): IoU = 0.644\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.567\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.455\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.521\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.521\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 14 | Step = 486 | Step Loss = 0.813\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.452\u001b[0m\n",
            "Class 1 (Building): IoU = 0.385\u001b[0m\n",
            "Class 2 (Road): IoU = 0.473\u001b[0m\n",
            "Class 3 (Water): IoU = 0.586\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.643\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.454\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.749\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.534\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 14 | Step = 504 | Step Loss = 1.027\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 14 | mean Loss = 0.856 | mean-IoU = 0.527\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.555\u001b[0m\n",
            "Class 1 (Building): IoU = 0.472\u001b[0m\n",
            "Class 2 (Road): IoU = 0.445\u001b[0m\n",
            "Class 3 (Water): IoU = 0.487\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.586\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.492\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.568\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.515\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 15 | Step = 522 | Step Loss = 0.782\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.559\u001b[0m\n",
            "Class 1 (Building): IoU = 0.421\u001b[0m\n",
            "Class 2 (Road): IoU = 0.421\u001b[0m\n",
            "Class 3 (Water): IoU = 0.651\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.645\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.546\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.638\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.554\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 15 | Step = 540 | Step Loss = 0.859\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 15 | mean Loss = 0.800 | mean-IoU = 0.553\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.601\u001b[0m\n",
            "Class 1 (Building): IoU = 0.430\u001b[0m\n",
            "Class 2 (Road): IoU = 0.445\u001b[0m\n",
            "Class 3 (Water): IoU = 0.421\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.780\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.513\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.694\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.555\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 16 | Step = 558 | Step Loss = 0.723\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.561\u001b[0m\n",
            "Class 1 (Building): IoU = 0.428\u001b[0m\n",
            "Class 2 (Road): IoU = 0.502\u001b[0m\n",
            "Class 3 (Water): IoU = 0.467\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.671\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.581\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.543\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.536\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 16 | Step = 576 | Step Loss = 0.785\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 16 | mean Loss = 0.757 | mean-IoU = 0.572\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.577\u001b[0m\n",
            "Class 1 (Building): IoU = 0.493\u001b[0m\n",
            "Class 2 (Road): IoU = 0.449\u001b[0m\n",
            "Class 3 (Water): IoU = 0.468\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.713\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.555\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.637\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.556\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 17 | Step = 594 | Step Loss = 0.742\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.483\u001b[0m\n",
            "Class 1 (Building): IoU = 0.452\u001b[0m\n",
            "Class 2 (Road): IoU = 0.546\u001b[0m\n",
            "Class 3 (Water): IoU = 0.644\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.584\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.440\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.665\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.545\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 17 | Step = 612 | Step Loss = 0.883\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 17 | mean Loss = 0.787 | mean-IoU = 0.554\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.655\u001b[0m\n",
            "Class 1 (Building): IoU = 0.349\u001b[0m\n",
            "Class 2 (Road): IoU = 0.514\u001b[0m\n",
            "Class 3 (Water): IoU = 0.678\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.653\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.254\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.556\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.523\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 18 | Step = 630 | Step Loss = 0.803\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.472\u001b[0m\n",
            "Class 1 (Building): IoU = 0.498\u001b[0m\n",
            "Class 2 (Road): IoU = 0.454\u001b[0m\n",
            "Class 3 (Water): IoU = 0.525\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.414\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.350\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.913\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.518\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 18 | Step = 648 | Step Loss = 0.997\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 18 | mean Loss = 0.844 | mean-IoU = 0.548\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.607\u001b[0m\n",
            "Class 1 (Building): IoU = 0.264\u001b[0m\n",
            "Class 2 (Road): IoU = 0.437\u001b[0m\n",
            "Class 3 (Water): IoU = 0.568\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.743\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.546\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.667\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.547\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 19 | Step = 666 | Step Loss = 0.834\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.580\u001b[0m\n",
            "Class 1 (Building): IoU = 0.419\u001b[0m\n",
            "Class 2 (Road): IoU = 0.517\u001b[0m\n",
            "Class 3 (Water): IoU = 0.750\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.713\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.449\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.578\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.572\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 19 | Step = 684 | Step Loss = 0.758\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 19 | mean Loss = 0.757 | mean-IoU = 0.564\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.611\u001b[0m\n",
            "Class 1 (Building): IoU = 0.342\u001b[0m\n",
            "Class 2 (Road): IoU = 0.396\u001b[0m\n",
            "Class 3 (Water): IoU = 0.352\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.677\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.454\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.838\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.524\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 20 | Step = 702 | Step Loss = 0.880\u001b[0m\n",
            "\u001b[36m\u001b[22mClass-wise IoUs:\u001b[0m\n",
            "Class 0 (Background): IoU = 0.564\u001b[0m\n",
            "Class 1 (Building): IoU = 0.500\u001b[0m\n",
            "Class 2 (Road): IoU = 0.578\u001b[0m\n",
            "Class 3 (Water): IoU = 0.690\u001b[0m\n",
            "Class 4 (Barren): IoU = 0.610\u001b[0m\n",
            "Class 5 (Forest): IoU = 0.368\u001b[0m\n",
            "Class 6 (Agricultural): IoU = 0.759\u001b[0m\n",
            "\u001b[32m\u001b[2mMean IoU (mIoU): 0.581\u001b[0m\n",
            "\u001b[37m\u001b[2mTrain: Epoch = 20 | Step = 720 | Step Loss = 0.782\u001b[0m\n",
            "\u001b[30m\u001b[42m\u001b[1mTrain: Epoch = 20 | mean Loss = 0.813 | mean-IoU = 0.556\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PIDNet & LoveDA"
      ],
      "metadata": {
        "id": "H39hIKUEQtV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIDNet.models.pidnet import PIDNet\n",
        "pidnet_model = PIDNet(m=2, n=3, num_classes=NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)"
      ],
      "metadata": {
        "id": "-jN8CpnfQwEb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jftNKn4VtYB"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}